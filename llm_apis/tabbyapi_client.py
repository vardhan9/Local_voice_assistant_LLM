from openai import OpenAI
import os
from config_loader import config

class TabbyApiClient:
    """Client for interacting with TabbyAPI."""
    def __init__(self, verbose=False):
        key = os.getenv('TABBY_API_KEY')
        self.client = OpenAI(api_key=key if key != "" else None, base_url=config.TABBY_API_BASE_URL)
        self.verbose = verbose

    def stream_completion(self, messages, model, **kwargs):
        """Get completion from TabbyAPI.

        Args:
            messages (list): List of messages.
            model (str): Model for completion.
            **kwargs: Additional keyword arguments.

        Yields:
            str: Text generated by TabbyAPI.
        """
        try:
            stream = self.client.chat.completions.create(
                model=model,
                messages=messages,
                stream=True,
                **kwargs
            )
            for chunk in stream:
                content = chunk.choices[0].delta.content
                if content is not None:
                    yield content
        except Exception as e:
            if self.verbose:
                import traceback
                traceback.print_exc()
            else:
                print(f"An error occurred streaming completion from TabbyAPI: {e}")
            raise RuntimeError(f"An error occurred streaming completion from TabbyAPI: {e}")