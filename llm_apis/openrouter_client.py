from openai import OpenAI
from openai import APIError
import os
import base64
import httpx
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

class OpenRouterRateLimitError(Exception):
    """Exception raised for rate limit errors."""
    def __init__(self, message, retry_after):
        """
        Initialize the OpenRouterRateLimitError with a message and retry interval.

        Args:
            message (str): The error message to display.
            retry_after (int): The number of seconds to wait before retrying.
        """
        self.message = message
        self.retry_after = retry_after
        super().__init__(self.message)

class OpenRouterClient:
    """Client for interacting with the OpenRouter API."""

    def __init__(self, verbose=False):
        """Initialize the OpenRouter client with the API key."""
        base_url = "https://openrouter.ai/api/v1"
        api_key = os.getenv("OPENROUTER_API_KEY")  # Make sure to set this environment variable
        
        if not api_key:
            raise ValueError("OPENROUTER_API_KEY environment variable is not set")
            
        self.client = OpenAI(
            base_url=base_url,
            api_key=api_key,
            default_headers={
                "HTTP-Referer": "https://your-site-url.com",  # Required for OpenRouter
                "X-Title": "Your App Name"                    # Required for OpenRouter
            }
        )
        self.verbose = verbose

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        retry=retry_if_exception_type(OpenRouterRateLimitError)
    )
    def _make_api_call(self, model, processed_messages, **kwargs):
        """Make an API call with retry mechanism."""
        try:
            return self.client.chat.completions.create(
                model=model,
                messages=processed_messages,
                stream=True,
                **kwargs
            )
        except APIError as e:
            error_dict = e.response.json() if hasattr(e, 'response') else {}
            error_type = error_dict.get('error', {}).get('type')
            error_message = error_dict.get('error', {}).get('message', str(e))
            
            if error_type == 'model_rate_limit':
                retry_after = error_dict.get('error', {}).get('retry_after', 60)
                raise OpenRouterRateLimitError(f"Rate limit exceeded for model {model}. {error_message}", retry_after)
            raise

    def stream_completion(self, messages, model, **kwargs):
        """Stream completion from the OpenRouter API.
        
        Args:
            messages (list): List of messages.
            model (str): Model for completion.
            **kwargs: Additional keyword arguments.

        Yields:
            str: Text generated by the OpenRouter API.
        """
        # Process messages to handle multimodal content
        processed_messages = []
        for message in messages:
            content = []
            
            # Handle text content
            if isinstance(message.get('content'), str):
                content.append({"type": "text", "text": message['content']})
            elif isinstance(message.get('content'), list):
                for item in message['content']:
                    if item.get('type') == 'image':
                        content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{item['source']['media_type']};base64,{item['source']['data']}"
                            }
                        })
                    else:
                        content.append(item)
            
            processed_messages.append({
                "role": message['role'],
                "content": content if content else message.get('content')
            })

        try:
            stream = self._make_api_call(model, processed_messages, **kwargs)
            for chunk in stream:
                content = chunk.choices[0].delta.content
                if content is not None:
                    yield content
        except OpenRouterRateLimitError as e:
            print(f"Rate limit error: {e.message}. Retry after {e.retry_after} seconds.")
            raise
        except Exception as e:
            print(f"Unexpected error: {str(e)}")
            raise RuntimeError(f"An unexpected error occurred: {e}") from None

# Test the OpenRouterClient
if __name__ == "__main__":
    client = OpenRouterClient(verbose=True)
    
    #test text only   
    messages = [
        {
            "role": "system",
            "content": "Be precise and concise."
        },
        {
            "role": "user",
            "content": "What is the capital of France?"
        }
    ]
    model = "meta-llama/llama-3.2-11b-vision-instruct:free"  # or another vision-capable model

    print("\nText-only Response:")
    try:
        for chunk in client.stream_completion(messages, model):
            print(chunk, end='', flush=True)
        print()  # Add a newline at the end
    except OpenRouterRateLimitError as e:
        print(f"\nRate limit error encountered: {e.message}. Retry after {e.retry_after} seconds.")
    except Exception as e:
        print(f"\nAn error occurred: {e}")

    
    #test multimodal
    image_url = "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"
    image_data = base64.b64encode(httpx.get(image_url).content).decode("utf-8")
 
    messages = [
        {
            "role": "system",
            "content": "Respond only in rhyming couplets."
        },
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "Should I eat this?"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_data}"
                    }
                }
            ]
        }
    ]
   
    print("\nMultimodal Response:")
    try:
        for chunk in client.stream_completion(messages, model):
            print(chunk, end='', flush=True)
        print()
    except OpenRouterRateLimitError as e:
        print(f"\nRate limit error encountered: {e.message}. Retry after {e.retry_after} seconds.")
    except Exception as e:
        print(f"\nAn error occurred: {e}")
